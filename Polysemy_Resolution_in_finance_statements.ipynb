{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoisqualified/data-analysis-and-ml/blob/main/Polysemy_Resolution_in_finance_statements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline,BertModel\n",
        "from bs4 import BeautifulSoup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy"
      ],
      "metadata": {
        "id": "HKUF0VaAD0GW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdsBylmkcQUJ",
        "outputId": "d4440fc1-d3b5-4f7a-a9f3-b2e095818689"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "II6jmh5KqSq-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e8159dcd-4d09-4b7e-f72d-e010e07e4a0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence Sentiment\n",
              "0  The GeoSolutions technology will leverage Bene...  positive\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
              "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
              "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
              "4  The Swedish buyout firm has sold its remaining...   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b1aca18-7fc4-4696-9bfb-8281ab146986\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1aca18-7fc4-4696-9bfb-8281ab146986')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b1aca18-7fc4-4696-9bfb-8281ab146986 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b1aca18-7fc4-4696-9bfb-8281ab146986');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-491177ab-0cf8-4ea6-abab-e32e210285b4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-491177ab-0cf8-4ea6-abab-e32e210285b4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-491177ab-0cf8-4ea6-abab-e32e210285b4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5842,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5322,\n        \"samples\": [\n          \"It is now the leading private road ambulance service company in Finland .\",\n          \"Finnish silicon wafers manufacturer Okmetic Oyj said it swung to a net profit of 4.9 mln euro $ 6.3 mln in the first nine months of 2006 from a net loss of 1.8 mln euro $ 2.3 mln a year earlier .\",\n          \"$GILD  is expanding its research facilities...keeping up with the pace of innovation  https://t.co/uOE7FJ4LOP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URLs of the website to scrape\n",
        "url = \"https://www.cnbc.com/finance/\"\n",
        "\n",
        "\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "headlines = soup.find_all(\"a\", attrs={'class':'Card-title'})\n",
        "\n",
        "for headline in headlines:\n",
        "    print(headline.text)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    headlines = soup.find_all('a', class_='LatestNews-headline')\n",
        "\n",
        "    # Print the headlines\n",
        "    for headline in headlines:\n",
        "        print(headline.get_text())\n",
        "\n",
        "else:\n",
        "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "UGHBbwCAoFE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17774643-10e4-4938-834d-fab58567938c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Federal Reserve says all 31 banks in annual stress test withstood a severe hypothetical downturn\n",
            "Stocks making biggest moves midday: Rivian Automotive, FedEx, Whirlpool and more\n",
            "Morgan Stanley advisors about to get an OpenAI-powered assistant for grunt work\n",
            "Stocks making the biggest moves premarket: Rivian, Nvidia, Micron, FedEx\n",
            "China's EV architect says investing in Europe is a way forward\n",
            "Your 401(k) is higher, but a new report says Americans need to save even more \n",
            "Europe is at risk of over-restricting AI and falling behind U.S. and China, Dutch prince says Â \n",
            "China's yuan internationalization needs more 'applications,' HKEX CEO\n",
            "Stocks making the biggest moves midday: SolarEdge, Pool Corp., Carnival and more\n",
            "Fewer Americans are buying life insurance. Here's when you might need it\n",
            "Cisco is 'very optimistic' about its growing business with China EVs\n",
            "Stocks making the biggest moves midday: ResMed, Nvidia, Anheuser-Busch and more\n",
            "Stocks making the biggest moves before the bell: Nvidia, Ferrari, Planet Fitness\n",
            "China growth worries have hit a big alcohol stock. Why some analysts see a buy opportunity\n",
            "Regulators hit Citigroup, JPMorgan, Goldman and Bank of America on living wills\n",
            "Stocks are in longest stretch without a 2% sell-off since the financial crisis\n",
            "Stocks making the biggest moves midday: Sarepta Therapeutics, Hertz, Asana\n",
            "Nearly $109 million in deposits held for fintech Yotta users vanished, bank says\n",
            "Stocks making the biggest moves premarket: Gilead Sciences, Sarepta Therapeutics, Nike and more\n",
            "China has spent at least $230 billion to build its EV industry, new study finds\n",
            "China talks up support for IPOs. Investors are watching the speed of approval\n",
            "How investors can stay protected with emerging market opportunities\n",
            "Stocks making the biggest moves midday: Gilead, Accenture, Trump Media and more\n",
            "More states poised to roll out Inflation Reduction Act energy rebates this summer\n",
            "Super Micro, Dell shares jump as Elon Musk says they are supplying xAI\n",
            "Stocks making the biggest moves premarket: Nvidia, Trump Media, Accenture and more\n",
            "Fitch pushes back China rate cut expectations as Fed holds interest rates steady\n",
            "Zilch raises $125 million with aim to triple sales and accelerate path to IPO\n",
            "Steve Cohen is set to make a big push into investing in AI\n",
            "Stocks making the biggest moves midday: La-Z-Boy, Rocket Lab USA and more\n",
            "Investors are the most bullish since November 2021, widely followed survey shows\n",
            "American households have seen their purchasing power increase\n",
            "Google's Android apps are coming in 3D via Xreal as competition with Apple heats up\n",
            "Warren Buffett buys Occidental shares for 9 days, pushes his stake to nearly 29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "# model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')\n",
        "\n",
        "# headlines = ['We are hoping to break-even in the next quarter',\n",
        "#              'The investment firm is bullish on the prospects of renewable energy',\n",
        "#              'We faced a bear market which impacted stocks',]\n",
        "\n",
        "# for headline in headlines:\n",
        "#   inputs = tokenizer(headline, return_tensors=\"pt\")\n",
        "#   outputs = model(**inputs)\n",
        "#   probs = torch.nn.functional.softmax(outputs.logits, dim = -1)\n",
        "#   labels = ['positive','neutral','negative']\n",
        "#   sentiment = labels[torch.argmax(probs)]\n",
        "#   print(f'Sentiment:{sentiment}')"
      ],
      "metadata": {
        "id": "PIv77JnAKR4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FinBERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "model = BertModel.from_pretrained('yiyanghkust/finbert-tone')\n",
        "\n",
        "sentence = \"We faced a bear market which impacted stocks\"\n",
        "target_word = \"bear\"\n",
        "\n",
        "# Tokenize and get the embeddings\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Get the token embeddings from the last hidden state\n",
        "token_embeddings = outputs.last_hidden_state[0]\n",
        "\n",
        "# Get the token IDs and find the index of the target word\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "target_idx = tokens.index(target_word)\n",
        "\n",
        "# Extract the embedding for the target word\n",
        "target_embedding = token_embeddings[target_idx].detach().numpy()\n",
        "\n",
        "# Define a set of financial terms (this can be expanded)\n",
        "financial_terms = [\"bull\", \"bear\", \"market\", \"stocks\", \"investment\", \"equity\", \"shares\", \"debt\", \"bond\", \"loss\"]\n",
        "\n",
        "# Tokenize and get the embeddings for financial terms\n",
        "financial_embeddings = {}\n",
        "for term in financial_terms:\n",
        "    term_inputs = tokenizer(term, return_tensors=\"pt\", add_special_tokens=False)\n",
        "    term_outputs = model(**term_inputs)\n",
        "    term_embedding = term_outputs.last_hidden_state[0][0].detach().numpy()\n",
        "    financial_embeddings[term] = term_embedding\n",
        "\n",
        "# Compute cosine similarity between the target word and financial terms\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "similarities = {}\n",
        "for term, embedding in financial_embeddings.items():\n",
        "    similarity = cosine_similarity(target_embedding, embedding)\n",
        "    similarities[term] = similarity\n",
        "\n",
        "# Sort terms by similarity\n",
        "sorted_terms = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Print the top similar terms\n",
        "print(f\"Top words similar to '{target_word}' in the financial context:\")\n",
        "for term, similarity in sorted_terms:\n",
        "    print(f\"{term}: {similarity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC9v3Y1UBV80",
        "outputId": "a9451614-d2d9-4979-b0da-3afce715a523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words similar to 'bear' in the financial context:\n",
            "bear: 0.2275\n",
            "market: 0.1543\n",
            "loss: 0.1497\n",
            "bull: 0.1378\n",
            "bond: 0.1166\n",
            "investment: 0.0545\n",
            "debt: 0.0417\n",
            "stocks: 0.0294\n",
            "shares: 0.0171\n",
            "equity: 0.0146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "# Load FinBERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
        "model = BertModel.from_pretrained('yiyanghkust/finbert-tone')\n",
        "\n",
        "# Load spaCy for POS tagging\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sentence to analyze\n",
        "sentence = \"We faced a bear market which impacted stocks.\"\n",
        "\n",
        "# Define a set of financial terms for each noun\n",
        "financial_terms_bear_market = [\n",
        "    \"downturn\", \"recession\", \"decline\", \"slump\", \"bearish trend\", \"negative market\",\n",
        "    \"market dip\", \"market crash\", \"economic downturn\", \"depressed market\"\n",
        "]\n",
        "\n",
        "financial_terms_stocks = [\n",
        "    \"equities\", \"shares\", \"securities\", \"holdings\", \"equity securities\", \"common stock\",\n",
        "    \"preferred stock\", \"corporate stock\", \"public stock\", \"trading shares\"\n",
        "]\n",
        "\n",
        "financial_terms_market = [\n",
        "    \"exchange\", \"bourse\", \"trading floor\", \"marketplace\", \"securities market\",\n",
        "    \"stock market\", \"equity market\", \"bond market\", \"commodities market\",\n",
        "    \"forex\", \"financial market\", \"capital market\", \"derivatives market\",\n",
        "    \"futures market\", \"options market\", \"OTC market\", \"primary market\", \"secondary market\"\n",
        "]\n",
        "\n",
        "financial_terms = {\n",
        "    \"bear\": financial_terms_bear_market,\n",
        "    \"market\": financial_terms_market,\n",
        "    \"stocks\": financial_terms_stocks\n",
        "}\n",
        "\n",
        "# Perform POS tagging to identify potential target words\n",
        "doc = nlp(sentence)\n",
        "target_words = [token.text for token in doc if token.pos_ in [\"NOUN\", \"PROPN\"]]\n",
        "\n",
        "# Tokenize and get the embeddings for the sentence\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
        "outputs = model(**inputs)\n",
        "token_embeddings = outputs.last_hidden_state[0]\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "\n",
        "# Function to compute cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "# Tokenize and get the embeddings for financial terms\n",
        "financial_embeddings = {}\n",
        "for key, term_list in financial_terms.items():\n",
        "    for term in term_list:\n",
        "        term_inputs = tokenizer(term, return_tensors=\"pt\", add_special_tokens=False)\n",
        "        term_outputs = model(**term_inputs)\n",
        "        term_embedding = term_outputs.last_hidden_state[0][0].detach().numpy()\n",
        "        financial_embeddings[term] = term_embedding\n",
        "\n",
        "# Process each target word\n",
        "for target_word in target_words:\n",
        "    if target_word in tokens or f\"{tokens[tokens.index(target_word)-1]} {target_word}\" in financial_terms:\n",
        "        target_idx = tokens.index(target_word)\n",
        "        target_embedding = token_embeddings[target_idx].detach().numpy()\n",
        "\n",
        "        # Determine which financial terms list to use\n",
        "        if target_word in financial_terms:\n",
        "            term_list = financial_terms[target_word]\n",
        "        else:\n",
        "            term_list = financial_terms.get(f\"{tokens[tokens.index(target_word)-1]} {target_word}\", [])\n",
        "\n",
        "        # Compute similarities\n",
        "        similarities = {}\n",
        "        for term in term_list:\n",
        "            embedding = financial_embeddings[term]\n",
        "            similarity = cosine_similarity(target_embedding, embedding)\n",
        "            similarities[term] = similarity\n",
        "\n",
        "        # Sort terms by similarity\n",
        "        sorted_terms = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "        # Print the top similar terms\n",
        "        print(f\"Top words similar to '{target_word}' in the financial context:\")\n",
        "        for term, similarity in sorted_terms:\n",
        "            print(f\"{term}: {similarity:.4f}\")\n",
        "        print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS6u1n_5MGKW",
        "outputId": "c674f36e-dc2a-4fa1-cf87-0f70629b0f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words similar to 'bear' in the financial context:\n",
            "market dip: 0.2909\n",
            "negative market: 0.2841\n",
            "bearish trend: 0.2632\n",
            "market crash: 0.2140\n",
            "recession: 0.1942\n",
            "downturn: 0.1885\n",
            "depressed market: 0.1780\n",
            "slump: 0.1703\n",
            "economic downturn: 0.1442\n",
            "decline: 0.0912\n",
            "\n",
            "\n",
            "Top words similar to 'market' in the financial context:\n",
            "secondary market: 0.2586\n",
            "options market: 0.2476\n",
            "commodities market: 0.2303\n",
            "bourse: 0.2124\n",
            "forex: 0.2093\n",
            "trading floor: 0.2073\n",
            "financial market: 0.2065\n",
            "capital market: 0.1989\n",
            "OTC market: 0.1956\n",
            "derivatives market: 0.1933\n",
            "equity market: 0.1857\n",
            "primary market: 0.1802\n",
            "securities market: 0.1690\n",
            "marketplace: 0.1680\n",
            "bond market: 0.1552\n",
            "stock market: 0.1521\n",
            "exchange: 0.1511\n",
            "futures market: 0.1175\n",
            "\n",
            "\n",
            "Top words similar to 'stocks' in the financial context:\n",
            "equity securities: 0.2246\n",
            "corporate stock: 0.2130\n",
            "securities: 0.2098\n",
            "common stock: 0.1857\n",
            "public stock: 0.1756\n",
            "shares: 0.1576\n",
            "preferred stock: 0.1460\n",
            "trading shares: 0.1357\n",
            "equities: 0.1349\n",
            "holdings: 0.1222\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Download and load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.eval()\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(data, tokenizer, max_len=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for headline in data:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            headline,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# Preprocess the headlines\n",
        "input_ids, attention_masks = preprocess_data(data['final_headline'], tokenizer)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "labels = torch.tensor(data['label'].values)\n",
        "\n",
        "# Extract BERT embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_masks)\n",
        "    cls_embeddings = outputs[0][:, 0, :].numpy()\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(cls_embeddings, data['label'].values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(cls_embeddings.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "JZHNwW8knnrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Step 1: Text cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "data['cleaned_headline'] = data['headline'].apply(clean_text)\n",
        "\n",
        "# Step 2: Tokenization\n",
        "data['tokenized_headline'] = data['cleaned_headline'].apply(word_tokenize)\n",
        "\n",
        "# Step 3: Removing stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "data['headline_no_stopwords'] = data['tokenized_headline'].apply(remove_stopwords)\n",
        "\n",
        "# Step 4: Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "data['lemmatized_headline'] = data['headline_no_stopwords'].apply(lemmatize_tokens)\n",
        "\n",
        "# Step 5: Feature extraction (TF-IDF)\n",
        "data['final_headline'] = data['lemmatized_headline'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(data['final_headline'])\n",
        "\n",
        "# Convert the labels to a numpy array\n",
        "y = data['label'].values\n",
        "\n",
        "# Display the shapes of the features and labels\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "id": "BpAbtoD3nq6H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}